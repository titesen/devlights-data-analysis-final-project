# üìä Chinook Strategy Command Center: Soluci√≥n de Business Intelligence End-to-End

## üìë Tabla de Contenidos
- [Resumen](#-resumen-ejecutivo)
- [Contexto de negocio y problem√°tica](#-contexto-de-negocio-y-problem√°tica)
- [Marco estrat√©gico: OKRs y KPIs](#-marco-estrat√©gico-okrs-y-kpis)
- [Arquitectura de datos e ingenier√≠a](#Ô∏è-arquitectura-de-datos-e-ingenier√≠a)
- [Modelado dimensional (OLAP)](#-modelado-dimensional-olap)
- [An√°lisis profundo y segmentaci√≥n de clientes (RFM)](#-an√°lisis-profundo-y-segmentaci√≥n-de-clientes-rfm)
- [Descripci√≥n del dashboard e insights](#-descripci√≥n-del-dashboard-e-insights)
- [Stack tecnol√≥gico](#-stack-tecnol√≥gico)
- [Instalaci√≥n y despliegue](#-instalaci√≥n-y-despliegue)

## üöÄ Resumen 
Este proyecto presenta una soluci√≥n integral de Business Intelligence (BI) dise√±ada para transformar los datos transaccionales de una tienda de medios digitales (Chinook) en activos estrat√©gicos para la toma de decisiones.

Simulando un entorno corporativo real, se realiz√≥ una migraci√≥n completa de una arquitectura **OLTP** (On-Line Transaction Processing) hacia un **Data Warehouse OLAP** (On-Line Analytical Processing). El resultado es un sistema capaz de procesar vol√∫menes de datos hist√≥ricos, reducir la latencia de consulta y visualizar m√©tricas cr√≠ticas de negocio mediante un dashboard interactivo autogestionado.

## üè¢ Contexto de negocio y problem√°tica
**Chinook** es una tienda global de m√∫sica y video digital. A pesar de contar con una base de datos robusta, la organizaci√≥n sufr√≠a de "Ceguera Operativa":

- **Silos de datos**: La informaci√≥n estaba dispersa en tablas altamente normalizadas, dificultando la visi√≥n hol√≠stica.
- **Latencia en reportes**: Consultas anal√≠ticas complejas sobre el sistema transaccional degradaban el rendimiento de la operaci√≥n diaria.
- **Falta de segmentaci√≥n**: No exist√≠a una metodolog√≠a para identificar clientes de alto valor o riesgos de abandono (Churn).

**La soluci√≥n**: Implementaci√≥n de un pipeline ETL (Extract, Transform, Load) para consolidar una "Single Source of Truth" (SSOT) en un esquema dimensional optimizado para lectura.

## üéØ Marco estrat√©gico: OKRs y KPIs
El dise√±o del dashboard responde a objetivos estrat√©gicos definidos bajo la metodolog√≠a **OKR** (Objectives and Key Results):

### Objetivo 1: Maximizar la eficiencia de ingresos
**KR 1**: Monitorear el flujo de caja hist√≥rico y actual para identificar estacionalidades.
- **KPI principal**: Total Revenue (Ingresos Brutos).
- **KPI secundario**: AOV (Average Order Value) - Ticket promedio por transacci√≥n.

### Objetivo 2: Optimizaci√≥n de inventario y operaciones
**KR 1**: Identificar los formatos de archivo m√°s rentables vs. los que consumen almacenamiento innecesario.
- **KPI**: Profitability by Media Type.

### Objetivo 3: Retenci√≥n y fidelizaci√≥n de clientes
**KR 1**: Segmentar la base de usuarios basada en comportamiento de compra para personalizar estrategias de marketing.
- **KPI**: Customer Lifetime Value (CLV) proxies mediante segmentaci√≥n RFM.

## ‚öôÔ∏è Arquitectura de datos e ingenier√≠a
El flujo de trabajo sigue un enfoque de ingenier√≠a de datos moderno, orquestado mediante contenedores para asegurar la reproducibilidad.

### Flujo del pipeline (ETL)
1. **Extracci√≥n (Source)**: Se parte de una base de datos PostgreSQL en 3FN (Tercera Forma Normal). Este modelo relacional es eficiente para la integridad de datos (escritura) pero ineficiente para el an√°lisis (lectura) debido a la excesiva cantidad de JOINs necesarios.

2. **Transformaci√≥n (Staging Area)**: Mediante scripts SQL avanzados (DDL/DML), se limpian los datos, se desnormalizan tablas y se calculan m√©tricas pre-agregadas.

3. **Carga (Target)**: Los datos transformados se insertan en un esquema dimensional (Star Schema) dentro del Data Warehouse.

### Infraestructura (IaaS)
El proyecto se despliega sobre un servidor VPS Linux (Ubuntu 24.04) en la nube, utilizando **Docker Compose** para levantar una arquitectura multi-contenedor que incluye la base de datos y la plataforma de visualizaci√≥n (Metabase), interconectados en una red interna aislada.

## üìê Modelado dimensional (OLAP)
Para optimizar el rendimiento de las consultas anal√≠ticas, se dise√±√≥ un **Esquema de Estrella (Star Schema)**:

![Modelo OLTP](/assets/oltp_model.png)

*Modelo OLTP*

![Modelo OLAP (Esquema estrella)](/assets/olap_model.png)

*Modelo OLAP (Esquema estrella)*

- **Fact Table (fact_invoice_lines)**: Tabla central de hechos que contiene las m√©tricas cuantitativas (precios unitarios, cantidades, totales) y las llaves for√°neas.

- **Dimension tables**: Tablas satelitales desnormalizadas que aportan contexto:
  - `dim_customers`: Datos demogr√°ficos y ubicaci√≥n.
  - `dim_tracks`: Metadatos de las canciones, √°lbumes, g√©neros y tipos de medio.
  - `dim_time`: (Impl√≠cita) Para cortes temporales y an√°lisis de series de tiempo.
  - `dim_employees`: Jerarqu√≠a organizacional y ventas.

Este modelo reduce la complejidad de las consultas de **6+ JOINs** (en OLTP) a **1 o 2 uniones simples**, acelerando dr√°sticamente el tiempo de respuesta del dashboard.

## üíé An√°lisis profundo y segmentaci√≥n de clientes (RFM)
La "Joya de la Corona" de este an√°lisis es la implementaci√≥n de un algoritmo de **Segmentaci√≥n RFM** (Recencia, Frecuencia, Valor Monetario) utilizando SQL Avanzado.

### Metodolog√≠a t√©cnica
A diferencia de herramientas "caja negra", aqu√≠ se calcul√≥ la segmentaci√≥n manualmente en la base de datos utilizando:

- **CTEs (Common Table Expressions)**: Para aislar m√©tricas por cliente.
- **Window Functions (NTILE)**: Para dividir a la poblaci√≥n en cuartiles estad√≠sticos (scores del 1 al 4) en tres dimensiones:
  - **Recencia (R)**: ¬øHace cu√°nto compr√≥? (1 = Lejano, 4 = Reciente).
  - **Frecuencia (F)**: ¬øCu√°ntas veces compr√≥?
  - **Monetario (M)**: ¬øCu√°nto gast√≥ en total?

### Visualizaci√≥n e insights
Se construy√≥ un **Scatter Plot** (Matriz de Dispersi√≥n) correlacionando el Valor Monetario (Eje Y) vs. Frecuencia/Recencia (Eje X).

**Objetivo**: Identificar clusters de comportamiento para acciones t√°cticas.

**Insight clave**:
- **Campeones (Superior derecha)**: Clientes con alta frecuencia y alto gasto. **Acci√≥n**: Programas de fidelidad VIP.
- **En Riesgo (Superior izquierda)**: Clientes que gastaron mucho en el pasado pero no han vuelto (Baja Recencia). **Acci√≥n**: Campa√±as de reactivaci√≥n/Win-back agresivas.
- **Nuevos/Prometedores**: Clientes recientes con potencial de crecimiento.

## üìä Descripci√≥n del dashboard e insights
El tablero de control en **Metabase** se estructura en niveles de lectura:

1. **Filtros globales**: Permiten al usuario segmentar todo el reporte por Rango de Fechas y Pa√≠s de Facturaci√≥n (Billing Country), otorgando interactividad total.

2. **Health check (KPIs)**: Tarjetas num√©ricas con indicadores de Ingresos Totales y Promedio de Venta, permitiendo una evaluaci√≥n instant√°nea del estado financiero.

3. **An√°lisis geoespacial**: Mapa de calor que muestra la densidad de ventas por pa√≠s.
   - **Insight**: Am√©rica del Norte y Europa concentran el 80% del mercado, sugiriendo focalizar esfuerzos log√≠sticos y de marketing en estas zonas.

4. **An√°lisis de pareto (Formatos)**: Gr√°fico de barras que contrasta ingresos por tipo de archivo.
   - **Insight**: A pesar de almacenar archivos pesados (AAC/Lossless), el formato MPEG (MP3) genera la inmensa mayor√≠a de los ingresos. Esto sugiere una oportunidad de ahorro en costos de almacenamiento cloud eliminando formatos de baja rotaci√≥n.

5. **Performance de empleados**: Ranking de ventas por agente de soporte, √∫til para evaluaciones de desempe√±o y bonificaciones.

## üõ† Stack tecnol√≥gico
- **Base de datos**: PostgreSQL 16 (Motor relacional robusto).
- **Lenguajes**: SQL (PL/pgSQL para procedimientos almacenados), Bash (Scripting).
- **Infraestructura**: Docker & Docker Compose (Contenerizaci√≥n).
- **Cloud**: Ubuntu Server en VPS (Clouding.io).
- **Visualizaci√≥n**: Metabase (Business Intelligence Open Source).
- **Control de versiones**: Git & GitHub.

## üíª Instalaci√≥n y despliegue
Sigue estos pasos para desplegar el proyecto en tu entorno local:

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/tu-usuario/chinook-strategy-center.git
   cd chinook-strategy-center
   ```

2. **Configurar variables de entorno**: Renombrar el archivo `.env.example` a `.env` y configurar las credenciales de base de datos.

3. **Despliegue con Docker**:
   ```bash
   docker-compose up -d --build
   ```

4. **Ejecuci√≥n del ETL**: Acceder al contenedor de base de datos y ejecutar el script de migraci√≥n SQL provisto en `/scripts/etl_pipeline.sql`.

5. **Acceso**:
   - Metabase: http://localhost:3000
   - Base de datos: Puerto 5432

---

**Este proyecto fue desarrollado como trabajo final para el curso de Data Analytics en Devlights.**